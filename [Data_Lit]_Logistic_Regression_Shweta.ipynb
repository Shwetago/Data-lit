{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Data-Lit]_Logistic_Regression-Shweta.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "GXkJlR24gdPn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQ0bSEDwhuPm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  res = 1/(1 + np.exp(-z))\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfddEwPai9C6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(features, weights):\n",
        "  mult = np.dot(features, weights)\n",
        "  return sigmoid(mult)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q542C5zJjSyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cost_function(features, labels, weights):\n",
        "  \n",
        "  # Cost = (labels*log(predictions) + (1-labels)*log(1-predictions) ) / len(labels)\n",
        "  \n",
        "  observations = len(labels)\n",
        "  Pred = predict(features, weights)\n",
        "  \n",
        "  # Take error when label = 1\n",
        "  Cost1 = -labels * np.log(Pred)\n",
        "  \n",
        "  # Take error when label = 0\n",
        "  Cost2 = (1 - labels) * np.log(1 - Pred)\n",
        "  \n",
        "  Cost = Cost1 + Cost2\n",
        "  cost = Cost.sum() / observations\n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5AWH0PRpM4G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def update_weights(features, labels, weights, lr):\n",
        "  N = len(features)\n",
        "  \n",
        "  # Get predictions\n",
        "  Pred = predict(features, weights)\n",
        "  grad = np.dot(features.T, Pred - labels)\n",
        "  \n",
        "  # Take the average cost derivative for each feature\n",
        "  grad /= N\n",
        "  \n",
        "  # Multiply the gradient by our learning rate\n",
        "  grad *= lr\n",
        "  \n",
        "  # Subtract from our weights to minimize cost\n",
        "  weights -= grad\n",
        "  \n",
        "  return weights "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TbTQwV5momYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# With Sigmoid ranging from 0 to 1, the probability of 0.5 can be used as the decision boundary or threshold to determine the classes.\n",
        "\n",
        "def decision_boundary(prob):\n",
        "  return 1 if prob >= 0.5 else 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwYe9XOcXMcK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(predicted_labels, actual_labels):\n",
        "    diff = predicted_labels - actual_labels\n",
        "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQMXsK4uwfBC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_with_file(data_file, iters):\n",
        "  col = ['age','workclass','fnlgwt','education','education-num','marital-status',\n",
        "          'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
        "          'hours-per-week','native-country','income']\n",
        "  \n",
        "  Train = pd.read_csv(data_file, header=None, names = col)\n",
        "  \n",
        "  X_train = Train.iloc[:,:-1]\n",
        "  y_train = Train.iloc[:,-1]\n",
        "  \n",
        "  X_train.replace('?', np.nan, inplace=True)\n",
        "  y_train.replace('?', np.nan, inplace=True)\n",
        "  y_train = y_train.apply(lambda x: 1 if x == '>50K' else 0)\n",
        "  \n",
        "  X_train['workclass'].fillna('0', inplace=True)\n",
        "  X_train['occupation'].fillna('0', inplace=True)\n",
        "  X_train['native-country'].fillna('0', inplace=True)\n",
        "  \n",
        "  numerical = ['age', 'fnlgwt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "  categorical = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "  \n",
        "  p = dict(keys=numerical)\n",
        "  \n",
        "  # Creating dictionary\n",
        "  \n",
        "  for i in range(len(numerical)):\n",
        "    a = min(X_train[numerical[i]])\n",
        "    b = max(X_train[numerical[i]])\n",
        "    p[numerical[i]] = (a, b)\n",
        "    \n",
        "  for j in range(len(numerical)):\n",
        "    d = numerical[j]\n",
        "    X_train[d] = X_train[d].apply(lambda x: (x-p[d][0]) / ((p[d][1] - p[d][0])))\n",
        "    \n",
        "    X_train = pd.get_dummies(X_train)\n",
        "    \n",
        "    global clf\n",
        "    clf = X_train.columns\n",
        "    \n",
        "    weights = np.random.rand(X_train.shape[1])\n",
        "    cost_history = []\n",
        "    lr = 0.1\n",
        "    \n",
        "    for i in range(iters):\n",
        "      weights = update_weights(X_train, y_train, weights, lr)\n",
        "      \n",
        "      Cost = cost_function(X_train, y_train, weights)\n",
        "      cost_history.append(Cost)\n",
        "      \n",
        "    return weights, p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G9R5duQvLtgC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classify(data_file, weights, normalization_params):\n",
        "  col = ['age','workclass','fnlgwt','education','education-num','marital-status',\n",
        "          'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
        "          'hours-per-week','native-country','income']\n",
        "  \n",
        "  Test = pd.read_csv(data_file, names = col, skiprows=1)\n",
        "  \n",
        "  X_test = Test.iloc[:,:-1]\n",
        "  y_test = Test.iloc[:,-1]\n",
        "  \n",
        "  X_test.replace('?', np.nan, inplace=True)\n",
        "  y_test.replace('?', np.nan, inplace=True)\n",
        "  y_test = y_test.apply(lambda x: 1 if x == '>50K' else 0)\n",
        "  \n",
        "  X_test['workclass'].fillna('0', inplace=True)\n",
        "  X_test['occupation'].fillna('0', inplace=True)\n",
        "  X_test['native-country'].fillna('0', inplace=True)\n",
        "  \n",
        "  numerical = ['age', 'fnlgwt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "  categorical = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "  \n",
        "  N = normalization_params\n",
        "  for j in range(len(numerical)):\n",
        "    d = numerical[j]\n",
        "    X_test[d] = X_test[d].apply(lambda x: (x-N[d][0]) / ((N[d][1] - N[d][0])))\n",
        "    \n",
        "  X_test = pd.get_dummies(X_test)\n",
        "    \n",
        "  missing_cols = set(clf) - set(X_test.columns)\n",
        "  for w in missing_cols:\n",
        "    X_test[w] = 0\n",
        "  X_test = X_test[clf]\n",
        "\n",
        "  Pred = predict(X_test,weights)\n",
        "  Pred = np.array(list(map(decision_boundary,Pred)))\n",
        "\n",
        "  return Pred\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNHQY771ZiN5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_main():\n",
        "  weights, normalization_params = train_with_file('adult-training.csv', 1000)\n",
        "  labels = classify('adult-test.csv', weights, normalization_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MS73t2lQaSXe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}